{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .tsv to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    file = pd.read_csv(filename, sep='\\t')\n",
    "    data = [[file.iloc[i,0],file.iloc[i,1]] for i in range(len(file.index))]\n",
    "    file['label'] = file['label'].replace(['entailment', 'contradiction', 'neutral'], [0,1,2])\n",
    "    labels = file['label']\n",
    "#     file['genre'] = file['genre'].replace(['telephone', 'fiction', 'slate', 'government', 'travel'], [0,1,2,3,4])\n",
    "#     genres = file['genre']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data, train_targets = load_data('snli_train.tsv')\n",
    "val_data, val_targets = load_data('snli_val.tsv')\n",
    "file = pd.read_csv('snli_train.tsv', sep='\\t')\n",
    "file = file[:10000]\n",
    "# file['label']= file['label'].replace(['entailment', 'contradiction', 'neutral'], [0,1,2])\n",
    "# file.iloc[5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:10000]\n",
    "train_targets = train_targets[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = [[train_data[i][j].split() for j in range(2)] for i in range(len(train_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_tokens = [[val_data[i][j].split() for j in range(2)] for i in range(len(val_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1000\n"
     ]
    }
   ],
   "source": [
    "print (\"Train dataset size is {}\".format(len(train_data_tokens)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['A',\n",
       "  'young',\n",
       "  'girl',\n",
       "  'in',\n",
       "  'a',\n",
       "  'pink',\n",
       "  'shirt',\n",
       "  'sitting',\n",
       "  'on',\n",
       "  'a',\n",
       "  'dock',\n",
       "  'viewing',\n",
       "  'a',\n",
       "  'body',\n",
       "  'of',\n",
       "  'water',\n",
       "  '.'],\n",
       " ['A',\n",
       "  'young',\n",
       "  'girl',\n",
       "  'watching',\n",
       "  'the',\n",
       "  'sunset',\n",
       "  'over',\n",
       "  'the',\n",
       "  'water',\n",
       "  '.']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiki-news-300d-1M.vec') as f:\n",
    "    lines = []\n",
    "    for i in range(50001):\n",
    "        line = f.readline()\n",
    "        v = line.split()\n",
    "        for j in range(1,len(v)):\n",
    "            v[j] = float(v[j])\n",
    "        lines.append(v)\n",
    "        \n",
    "lines.remove(lines[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "word_dict['PAD'] = 0\n",
    "word_dict['UNK'] = 1\n",
    "\n",
    "embed = [[0 for i in range(300)],[0 for i in range(300)]]\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    word_dict['PAD'] = 0\n",
    "    word_dict['UNK'] = 1\n",
    "    word_dict[lines[i][0]] = i+2\n",
    "    embed.append(lines[i][1:])\n",
    "    \n",
    "embedding_matrix = np.matrix(embed)\n",
    "\n",
    "id2token = []\n",
    "for word in word_dict.keys():\n",
    "    id2token.append(word)\n",
    "token2id = word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50002\n"
     ]
    }
   ],
   "source": [
    "print(len(id2token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token id 26683 ; token handmade\n",
      "Token handmade; token id 26683\n"
     ]
    }
   ],
   "source": [
    "random_token_id = random.randint(0, len(id2token)-1)\n",
    "random_token = id2token[random_token_id]\n",
    "\n",
    "print (\"Token id {} ; token {}\".format(random_token_id, id2token[random_token_id]))\n",
    "print (\"Token {}; token id {}\".format(random_token, token2id[random_token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2token[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = 1\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        sublist = []\n",
    "        for i in range(2):\n",
    "            index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens[i]]\n",
    "            sublist.append(index_list)\n",
    "        indices_data.append(sublist)\n",
    "    return indices_data\n",
    "\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size is 10000\n",
      "Val dataset size is 1000\n"
     ]
    }
   ],
   "source": [
    "print (\"Train dataset size is {}\".format(len(train_data_indices)))\n",
    "print (\"Val dataset size is {}\".format(len(val_data_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[106,\n",
       "  802,\n",
       "  1830,\n",
       "  8,\n",
       "  9,\n",
       "  6265,\n",
       "  7167,\n",
       "  4388,\n",
       "  17,\n",
       "  9,\n",
       "  12229,\n",
       "  5335,\n",
       "  9,\n",
       "  563,\n",
       "  6,\n",
       "  358,\n",
       "  4],\n",
       " [106, 802, 1830, 2255, 3, 13985, 94, 3, 358, 4]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_indices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 25\n",
    "class SNLIDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx_1 = self.data_list[key][0][:MAX_SENTENCE_LENGTH]\n",
    "        token_idx_2 = self.data_list[key][1][:MAX_SENTENCE_LENGTH]\n",
    "        token_idx = [token_idx_1, token_idx_2]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, [len(token_idx_1), len(token_idx_2)], label]\n",
    "\n",
    "def SNLI_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec_1 = np.pad(np.array(datum[0][0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1][0])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec_2 = np.pad(np.array(datum[0][1]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1][1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "#         sublist = ' '.join(padded_vec_2)\n",
    "#         data_list.append(padded_vec_1)\n",
    "#         data_list.append(padded_vec_2)\n",
    "        data_list.append(list(padded_vec_1) + list(padded_vec_2))\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 40\n",
    "train_dataset = SNLIDataset(train_data_indices, train_targets)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SNLIDataset(val_data_indices, val_targets)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "tensor([[12,  7],\n",
      "        [11,  5],\n",
      "        [25, 12],\n",
      "        [16,  8],\n",
      "        [12,  5],\n",
      "        [11,  6],\n",
      "        [ 8, 10],\n",
      "        [20, 11],\n",
      "        [ 8,  5],\n",
      "        [ 9,  7],\n",
      "        [24,  5],\n",
      "        [25,  8],\n",
      "        [21,  6],\n",
      "        [ 7,  6],\n",
      "        [17,  9],\n",
      "        [21, 15],\n",
      "        [ 7,  8],\n",
      "        [15,  9],\n",
      "        [17,  8],\n",
      "        [ 9,  7],\n",
      "        [ 6,  6],\n",
      "        [ 9, 10],\n",
      "        [11,  5],\n",
      "        [10, 11],\n",
      "        [ 7,  8],\n",
      "        [20,  8],\n",
      "        [11,  7],\n",
      "        [ 9, 10],\n",
      "        [ 7,  7],\n",
      "        [ 8, 13],\n",
      "        [24, 11],\n",
      "        [15,  6],\n",
      "        [14,  6],\n",
      "        [20,  8],\n",
      "        [12,  5],\n",
      "        [14, 10],\n",
      "        [25, 11],\n",
      "        [ 7, 11],\n",
      "        [17, 11],\n",
      "        [12,  7]])\n",
      "tensor([ 1442,   884,   355,     8,   291,   606,  4301,    34,    17,     9,\n",
      "        14283,     4,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,  1442,   271,    34,    17,     9,\n",
      "        14283,     4,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "    print (len(data))\n",
    "    print (lengths)\n",
    "    break\n",
    "print (data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.FloatTensor(embed)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, vocab_size):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        # vocab_size: vocabulary size\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "#         self.rnn = nn.RNN(emb_size, hidden_size, num_layers, batch_first=True)#creating RNN in pytorch\n",
    "        self.bi_gru1 = nn.GRU(emb_size, hidden_size, num_layers=1, batch_first=True,bidirectional=True)\n",
    "        self.bi_gru2 = nn.GRU(emb_size, hidden_size, num_layers=1, batch_first=True,bidirectional=True)\n",
    "\n",
    "        # 2 FC layers\n",
    "        self.linear1 = nn.Linear(4 * hidden_size, 100)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        hidden = torch.zeros(self.num_layers*2, batch_size, self.hidden_size)\n",
    "        return hidden\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # reset hidden state\n",
    "\n",
    "        batch_size, seq_len = x.size()   \n",
    "        #main part of rnn\n",
    "        self.hidden1 = self.init_hidden(batch_size) # old size = batch_size \n",
    "        self.hidden2 = self.init_hidden(batch_size) # old size = batch_size \n",
    "\n",
    "        #######################################################\n",
    "        # code here\n",
    "        \n",
    "        # get embedding of characters\n",
    "        embed = self.embedding(x)\n",
    "        embed = self.dropout(embed)\n",
    "        embed.detach()\n",
    "        # sort the sequence\n",
    "        sorted_seq_lengths1, indices1 = torch.sort(lengths[:, 0], descending=True)\n",
    "        sorted_seq_lengths2, indices2 = torch.sort(lengths[:, 1], descending=True)\n",
    "        \n",
    "        embed_1 = embed[:, :MAX_SENTENCE_LENGTH, :][indices1]\n",
    "        embed_2 = embed[:, MAX_SENTENCE_LENGTH:, :][indices2]\n",
    "        \n",
    "        \n",
    "        embed_1 = torch.nn.utils.rnn.pack_padded_sequence(embed_1, \n",
    "                                                          sorted_seq_lengths1.numpy(), \n",
    "                                                          batch_first=True)\n",
    "        \n",
    "        embed_2 = torch.nn.utils.rnn.pack_padded_sequence(embed_2, \n",
    "                                                          sorted_seq_lengths2.numpy(), \n",
    "                                                          batch_first=True)\n",
    "\n",
    "        _, desorted_indices1 = torch.sort(indices1, descending=False)\n",
    "        _, desorted_indices2 = torch.sort(indices2, descending=False)\n",
    "        \n",
    "        #bi-directional GRU\n",
    "        bi_output1, self.hidden1 = self.bi_gru1(embed_1,self.hidden1)\n",
    "        bi_output2, self.hidden2 = self.bi_gru2(embed_2,self.hidden2)\n",
    "        # rearrange output into correct order\n",
    "#         print(self.hidden1.size())\n",
    "        self.hidden1 = self.hidden1[:, desorted_indices1, :]\n",
    "        self.hidden2 = self.hidden2[:, desorted_indices2, :]\n",
    "\n",
    "        \n",
    "        bi_gru_out = torch.cat((torch.cat([self.hidden1[0], self.hidden1[1]], dim=-1), \n",
    "                                torch.cat([self.hidden2[0], self.hidden2[1]], dim=-1)), dim=1)\n",
    "\n",
    "        # FC layers\n",
    "        rnn_out = self.linear1(bi_gru_out)\n",
    "        activate = self.activation(rnn_out)\n",
    "        logits = self.dropout(activate)\n",
    "        logits = self.linear2(logits)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "        #######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [101/2500], Validation Acc: 54.2\n",
      "Epoch: [1/10], Step: [201/2500], Validation Acc: 52.9\n",
      "Epoch: [1/10], Step: [301/2500], Validation Acc: 56.2\n",
      "Epoch: [1/10], Step: [401/2500], Validation Acc: 58.1\n",
      "Epoch: [1/10], Step: [501/2500], Validation Acc: 61.2\n",
      "Epoch: [1/10], Step: [601/2500], Validation Acc: 61.8\n",
      "Epoch: [1/10], Step: [701/2500], Validation Acc: 62.1\n",
      "Epoch: [1/10], Step: [801/2500], Validation Acc: 59.9\n",
      "Epoch: [1/10], Step: [901/2500], Validation Acc: 62.3\n",
      "Epoch: [1/10], Step: [1001/2500], Validation Acc: 61.5\n",
      "Epoch: [1/10], Step: [1101/2500], Validation Acc: 63.5\n",
      "Epoch: [1/10], Step: [1201/2500], Validation Acc: 63.1\n",
      "Epoch: [1/10], Step: [1301/2500], Validation Acc: 63.2\n",
      "Epoch: [1/10], Step: [1401/2500], Validation Acc: 62.8\n",
      "Epoch: [1/10], Step: [1501/2500], Validation Acc: 61.9\n",
      "Epoch: [1/10], Step: [1601/2500], Validation Acc: 63.2\n",
      "Epoch: [1/10], Step: [1701/2500], Validation Acc: 64.6\n",
      "Epoch: [1/10], Step: [1801/2500], Validation Acc: 63.1\n",
      "Epoch: [1/10], Step: [1901/2500], Validation Acc: 60.9\n",
      "Epoch: [1/10], Step: [2001/2500], Validation Acc: 63.6\n",
      "Epoch: [1/10], Step: [2101/2500], Validation Acc: 64.6\n",
      "Epoch: [1/10], Step: [2201/2500], Validation Acc: 64.7\n",
      "Epoch: [1/10], Step: [2301/2500], Validation Acc: 62.6\n",
      "Epoch: [1/10], Step: [2401/2500], Validation Acc: 63.1\n",
      "Epoch: [2/10], Step: [101/2500], Validation Acc: 67.4\n",
      "Epoch: [2/10], Step: [201/2500], Validation Acc: 64.5\n",
      "Epoch: [2/10], Step: [301/2500], Validation Acc: 64.3\n",
      "Epoch: [2/10], Step: [401/2500], Validation Acc: 66.3\n",
      "Epoch: [2/10], Step: [501/2500], Validation Acc: 65.5\n",
      "Epoch: [2/10], Step: [601/2500], Validation Acc: 65.8\n",
      "Epoch: [2/10], Step: [701/2500], Validation Acc: 67.8\n",
      "Epoch: [2/10], Step: [801/2500], Validation Acc: 66.9\n",
      "Epoch: [2/10], Step: [901/2500], Validation Acc: 65.6\n",
      "Epoch: [2/10], Step: [1001/2500], Validation Acc: 67.3\n",
      "Epoch: [2/10], Step: [1101/2500], Validation Acc: 65.8\n",
      "Epoch: [2/10], Step: [1201/2500], Validation Acc: 66.9\n",
      "Epoch: [2/10], Step: [1301/2500], Validation Acc: 66.0\n",
      "Epoch: [2/10], Step: [1401/2500], Validation Acc: 68.3\n",
      "Epoch: [2/10], Step: [1501/2500], Validation Acc: 66.9\n",
      "Epoch: [2/10], Step: [1601/2500], Validation Acc: 67.6\n",
      "Epoch: [2/10], Step: [1701/2500], Validation Acc: 68.2\n",
      "Epoch: [2/10], Step: [1801/2500], Validation Acc: 66.3\n",
      "Epoch: [2/10], Step: [1901/2500], Validation Acc: 67.8\n",
      "Epoch: [2/10], Step: [2001/2500], Validation Acc: 67.4\n",
      "Epoch: [2/10], Step: [2101/2500], Validation Acc: 66.4\n",
      "Epoch: [2/10], Step: [2201/2500], Validation Acc: 67.9\n",
      "Epoch: [2/10], Step: [2301/2500], Validation Acc: 67.9\n",
      "Epoch: [2/10], Step: [2401/2500], Validation Acc: 67.8\n",
      "Epoch: [3/10], Step: [101/2500], Validation Acc: 68.7\n",
      "Epoch: [3/10], Step: [201/2500], Validation Acc: 67.3\n",
      "Epoch: [3/10], Step: [301/2500], Validation Acc: 68.2\n",
      "Epoch: [3/10], Step: [401/2500], Validation Acc: 67.1\n",
      "Epoch: [3/10], Step: [501/2500], Validation Acc: 68.0\n",
      "Epoch: [3/10], Step: [601/2500], Validation Acc: 68.9\n",
      "Epoch: [3/10], Step: [701/2500], Validation Acc: 66.2\n",
      "Epoch: [3/10], Step: [801/2500], Validation Acc: 67.5\n",
      "Epoch: [3/10], Step: [901/2500], Validation Acc: 69.4\n",
      "Epoch: [3/10], Step: [1001/2500], Validation Acc: 68.4\n",
      "Epoch: [3/10], Step: [1101/2500], Validation Acc: 68.3\n",
      "Epoch: [3/10], Step: [1201/2500], Validation Acc: 68.2\n",
      "Epoch: [3/10], Step: [1301/2500], Validation Acc: 69.1\n",
      "Epoch: [3/10], Step: [1401/2500], Validation Acc: 68.1\n",
      "Epoch: [3/10], Step: [1501/2500], Validation Acc: 68.5\n",
      "Epoch: [3/10], Step: [1601/2500], Validation Acc: 67.6\n",
      "Epoch: [3/10], Step: [1701/2500], Validation Acc: 68.1\n",
      "Epoch: [3/10], Step: [1801/2500], Validation Acc: 67.1\n",
      "Epoch: [3/10], Step: [1901/2500], Validation Acc: 67.6\n",
      "Epoch: [3/10], Step: [2001/2500], Validation Acc: 67.9\n",
      "Epoch: [3/10], Step: [2101/2500], Validation Acc: 68.4\n",
      "Epoch: [3/10], Step: [2201/2500], Validation Acc: 69.0\n",
      "Epoch: [3/10], Step: [2301/2500], Validation Acc: 68.5\n",
      "Epoch: [3/10], Step: [2401/2500], Validation Acc: 68.5\n",
      "Epoch: [4/10], Step: [101/2500], Validation Acc: 69.2\n",
      "Epoch: [4/10], Step: [201/2500], Validation Acc: 68.2\n",
      "Epoch: [4/10], Step: [301/2500], Validation Acc: 68.8\n",
      "Epoch: [4/10], Step: [401/2500], Validation Acc: 68.1\n",
      "Epoch: [4/10], Step: [501/2500], Validation Acc: 68.9\n",
      "Epoch: [4/10], Step: [601/2500], Validation Acc: 69.4\n",
      "Epoch: [4/10], Step: [701/2500], Validation Acc: 68.6\n",
      "Epoch: [4/10], Step: [801/2500], Validation Acc: 67.8\n",
      "Epoch: [4/10], Step: [901/2500], Validation Acc: 68.2\n",
      "Epoch: [4/10], Step: [1001/2500], Validation Acc: 68.5\n",
      "Epoch: [4/10], Step: [1101/2500], Validation Acc: 68.3\n",
      "Epoch: [4/10], Step: [1201/2500], Validation Acc: 68.5\n",
      "Epoch: [4/10], Step: [1301/2500], Validation Acc: 69.3\n",
      "Epoch: [4/10], Step: [1401/2500], Validation Acc: 68.7\n",
      "Epoch: [4/10], Step: [1501/2500], Validation Acc: 70.5\n",
      "Epoch: [4/10], Step: [1601/2500], Validation Acc: 71.2\n",
      "Epoch: [4/10], Step: [1701/2500], Validation Acc: 70.0\n",
      "Epoch: [4/10], Step: [1801/2500], Validation Acc: 69.5\n",
      "Epoch: [4/10], Step: [1901/2500], Validation Acc: 68.4\n",
      "Epoch: [4/10], Step: [2001/2500], Validation Acc: 69.8\n",
      "Epoch: [4/10], Step: [2101/2500], Validation Acc: 69.3\n",
      "Epoch: [4/10], Step: [2201/2500], Validation Acc: 67.7\n",
      "Epoch: [4/10], Step: [2301/2500], Validation Acc: 67.9\n",
      "Epoch: [4/10], Step: [2401/2500], Validation Acc: 69.2\n",
      "Epoch: [5/10], Step: [101/2500], Validation Acc: 67.9\n",
      "Epoch: [5/10], Step: [201/2500], Validation Acc: 67.8\n",
      "Epoch: [5/10], Step: [301/2500], Validation Acc: 67.4\n",
      "Epoch: [5/10], Step: [401/2500], Validation Acc: 66.8\n",
      "Epoch: [5/10], Step: [501/2500], Validation Acc: 68.8\n",
      "Epoch: [5/10], Step: [601/2500], Validation Acc: 68.4\n",
      "Epoch: [5/10], Step: [701/2500], Validation Acc: 68.3\n",
      "Epoch: [5/10], Step: [801/2500], Validation Acc: 69.4\n",
      "Epoch: [5/10], Step: [901/2500], Validation Acc: 69.7\n",
      "Epoch: [5/10], Step: [1001/2500], Validation Acc: 68.7\n",
      "Epoch: [5/10], Step: [1101/2500], Validation Acc: 67.4\n",
      "Epoch: [5/10], Step: [1201/2500], Validation Acc: 66.6\n",
      "Epoch: [5/10], Step: [1301/2500], Validation Acc: 68.5\n",
      "Epoch: [5/10], Step: [1401/2500], Validation Acc: 68.3\n",
      "Epoch: [5/10], Step: [1501/2500], Validation Acc: 69.0\n",
      "Epoch: [5/10], Step: [1601/2500], Validation Acc: 68.9\n",
      "Epoch: [5/10], Step: [1701/2500], Validation Acc: 68.7\n",
      "Epoch: [5/10], Step: [1801/2500], Validation Acc: 69.6\n",
      "Epoch: [5/10], Step: [1901/2500], Validation Acc: 69.5\n",
      "Epoch: [5/10], Step: [2001/2500], Validation Acc: 68.8\n",
      "Epoch: [5/10], Step: [2101/2500], Validation Acc: 68.5\n",
      "Epoch: [5/10], Step: [2201/2500], Validation Acc: 67.9\n",
      "Epoch: [5/10], Step: [2301/2500], Validation Acc: 68.6\n",
      "Epoch: [5/10], Step: [2401/2500], Validation Acc: 68.4\n",
      "Epoch: [6/10], Step: [101/2500], Validation Acc: 68.9\n",
      "Epoch: [6/10], Step: [201/2500], Validation Acc: 68.7\n",
      "Epoch: [6/10], Step: [301/2500], Validation Acc: 67.6\n",
      "Epoch: [6/10], Step: [401/2500], Validation Acc: 66.9\n",
      "Epoch: [6/10], Step: [501/2500], Validation Acc: 67.9\n",
      "Epoch: [6/10], Step: [601/2500], Validation Acc: 67.6\n",
      "Epoch: [6/10], Step: [701/2500], Validation Acc: 67.9\n",
      "Epoch: [6/10], Step: [801/2500], Validation Acc: 68.1\n",
      "Epoch: [6/10], Step: [901/2500], Validation Acc: 68.4\n",
      "Epoch: [6/10], Step: [1001/2500], Validation Acc: 69.2\n",
      "Epoch: [6/10], Step: [1101/2500], Validation Acc: 67.1\n",
      "Epoch: [6/10], Step: [1201/2500], Validation Acc: 66.7\n",
      "Epoch: [6/10], Step: [1301/2500], Validation Acc: 67.1\n",
      "Epoch: [6/10], Step: [1401/2500], Validation Acc: 67.1\n",
      "Epoch: [6/10], Step: [1501/2500], Validation Acc: 67.3\n",
      "Epoch: [6/10], Step: [1601/2500], Validation Acc: 67.8\n",
      "Epoch: [6/10], Step: [1701/2500], Validation Acc: 67.6\n",
      "Epoch: [6/10], Step: [1801/2500], Validation Acc: 68.0\n",
      "Epoch: [6/10], Step: [1901/2500], Validation Acc: 68.7\n",
      "Epoch: [6/10], Step: [2001/2500], Validation Acc: 67.5\n",
      "Epoch: [6/10], Step: [2101/2500], Validation Acc: 66.9\n",
      "Epoch: [6/10], Step: [2201/2500], Validation Acc: 68.9\n",
      "Epoch: [6/10], Step: [2301/2500], Validation Acc: 68.1\n",
      "Epoch: [6/10], Step: [2401/2500], Validation Acc: 67.6\n",
      "Epoch: [7/10], Step: [101/2500], Validation Acc: 67.2\n",
      "Epoch: [7/10], Step: [201/2500], Validation Acc: 69.0\n",
      "Epoch: [7/10], Step: [301/2500], Validation Acc: 69.0\n",
      "Epoch: [7/10], Step: [401/2500], Validation Acc: 68.4\n",
      "Epoch: [7/10], Step: [501/2500], Validation Acc: 68.6\n",
      "Epoch: [7/10], Step: [601/2500], Validation Acc: 68.5\n",
      "Epoch: [7/10], Step: [701/2500], Validation Acc: 67.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [7/10], Step: [801/2500], Validation Acc: 66.1\n",
      "Epoch: [7/10], Step: [901/2500], Validation Acc: 68.0\n",
      "Epoch: [7/10], Step: [1001/2500], Validation Acc: 68.0\n",
      "Epoch: [7/10], Step: [1101/2500], Validation Acc: 68.0\n",
      "Epoch: [7/10], Step: [1201/2500], Validation Acc: 67.0\n",
      "Epoch: [7/10], Step: [1301/2500], Validation Acc: 67.5\n",
      "Epoch: [7/10], Step: [1401/2500], Validation Acc: 67.9\n",
      "Epoch: [7/10], Step: [1501/2500], Validation Acc: 67.2\n",
      "Epoch: [7/10], Step: [1601/2500], Validation Acc: 68.1\n",
      "Epoch: [7/10], Step: [1701/2500], Validation Acc: 67.2\n",
      "Epoch: [7/10], Step: [1801/2500], Validation Acc: 68.1\n",
      "Epoch: [7/10], Step: [1901/2500], Validation Acc: 66.8\n",
      "Epoch: [7/10], Step: [2001/2500], Validation Acc: 68.3\n",
      "Epoch: [7/10], Step: [2101/2500], Validation Acc: 67.2\n",
      "Epoch: [7/10], Step: [2201/2500], Validation Acc: 68.2\n",
      "Epoch: [7/10], Step: [2301/2500], Validation Acc: 67.0\n",
      "Epoch: [7/10], Step: [2401/2500], Validation Acc: 67.1\n",
      "Epoch: [8/10], Step: [101/2500], Validation Acc: 67.6\n",
      "Epoch: [8/10], Step: [201/2500], Validation Acc: 67.6\n",
      "Epoch: [8/10], Step: [301/2500], Validation Acc: 68.3\n",
      "Epoch: [8/10], Step: [401/2500], Validation Acc: 68.7\n",
      "Epoch: [8/10], Step: [501/2500], Validation Acc: 67.3\n",
      "Epoch: [8/10], Step: [601/2500], Validation Acc: 66.4\n",
      "Epoch: [8/10], Step: [701/2500], Validation Acc: 66.3\n",
      "Epoch: [8/10], Step: [801/2500], Validation Acc: 67.6\n",
      "Epoch: [8/10], Step: [901/2500], Validation Acc: 67.6\n",
      "Epoch: [8/10], Step: [1001/2500], Validation Acc: 66.7\n",
      "Epoch: [8/10], Step: [1101/2500], Validation Acc: 67.0\n",
      "Epoch: [8/10], Step: [1201/2500], Validation Acc: 67.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-e351b75c638b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-00c2d91f3175>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m#bi-directional GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mbi_output1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbi_gru1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mbi_output2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbi_gru2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# rearrange output into correct order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#         print(self.hidden1.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mflat_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mGRUCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mgi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mgh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mi_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mh_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, lengths_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, lengths_batch), dim=1)\n",
    "#         print(model(data_batch, lengths_batch))\n",
    "#         print(outputs)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)\n",
    "\n",
    "\n",
    "model = RNN(emb_size=300, hidden_size=300, num_layers=1, num_classes=3, vocab_size=len(id2token)) # num_layers\n",
    "\n",
    "learning_rate = 0.005\n",
    "num_epochs = 10 # number epoch to train\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "parameters = itertools.filterfalse(lambda p: p.requires_grad == False, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "loss_l = []\n",
    "acc_l = []\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(data,lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        if i % 64 == 0:\n",
    "            loss_l.append(loss.item())\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "            acc_l.append(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a887673ce147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_l' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(loss_l)\n",
    "plt.show()\n",
    "loss_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(emb_size=300, hidden_size=600, num_layers=1, num_classes=3, vocab_size=len(id2token))\n",
    "model.load_state_dict(torch.load('rnnmodel.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted:tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [2]])\n",
      "label:tensor([[1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    i = 0\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "        print('predicted:{}'.format(predicted))\n",
    "        print('label:{}'.format(labels.view_as(predicted)))\n",
    "        i +=1\n",
    "        if i >=1:\n",
    "            break\n",
    "    return (100 * correct / total)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "val_acc = test_model(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv('snli_val.tsv', sep='\\t')\n",
    "file = file[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Three women on a stage , one wearing red shoes...</td>\n",
       "      <td>There are two women standing on the stage</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Four people sit on a subway two read books , o...</td>\n",
       "      <td>Multiple people are on a subway together , wit...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bicycles stationed while a group of people soc...</td>\n",
       "      <td>People get together near a stand of bicycles .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man in overalls with two horses .</td>\n",
       "      <td>a man in overalls with two horses</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man observes a wavelength given off by an elec...</td>\n",
       "      <td>The man is examining what wavelength is given ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Two people are in a green forest .</td>\n",
       "      <td>The forest is not dead .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Two men are listening to music through headpho...</td>\n",
       "      <td>Two men listen to music .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Two women , one walking her dog the other push...</td>\n",
       "      <td>There is a snowstorm .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A group of numbered participants walk down the...</td>\n",
       "      <td>Participants wait for the beginning of the wal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Three people and a white dog are sitting in th...</td>\n",
       "      <td>Three dogs and a person are sitting in the snow .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A man wearing glasses is vacuuming an architec...</td>\n",
       "      <td>There is a man vaucuming</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A large group of people stand outside on a roa...</td>\n",
       "      <td>One group of people are watching what another ...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A little boy watches a Ferris Wheel in motion .</td>\n",
       "      <td>A boy is waiting in line for the Ferris Wheel .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Man in white shirt and blue jeans looking to t...</td>\n",
       "      <td>Man has a blue shirt on .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A man in a dark floral shirt and black jeans w...</td>\n",
       "      <td>A man walks past a newly painted mural of a wo...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Two men help an injured player on the field .</td>\n",
       "      <td>Some men help an injured player on the field .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A woman in a light blue jacket is riding a bike .</td>\n",
       "      <td>A woman in a jacket riding a bike to work .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A group of people dressed in Santa Claus suits...</td>\n",
       "      <td>A band plays at a beach party .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A red jeep hangs from the edge of a rocky clif...</td>\n",
       "      <td>The vehicle is red .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Two kids on a boat , one with a paddle , and t...</td>\n",
       "      <td>A kid is wearing a life vest .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>A woman is sitting in a street market stand wh...</td>\n",
       "      <td>The woman is in a street market .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A group of people are sitting under umbrellas ...</td>\n",
       "      <td>It is a saturday</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A boy riding on a carnival ride turns around f...</td>\n",
       "      <td>A human riding</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>People walk amongst a traffic jam in a crowded...</td>\n",
       "      <td>The traffic is halted and people are walking b...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A live band on a lawn jamming out .</td>\n",
       "      <td>A band is practicing new tunes in the garage .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>man grilling fish on barbecue</td>\n",
       "      <td>The man likes to eat fish .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A lone , 2-3 year old blond child in a blue ja...</td>\n",
       "      <td>The couch is pointed toward the front .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>A chef speaks into a microphone about a mixed ...</td>\n",
       "      <td>a chef speaks into a microphone near a bowl</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Many people are smiling as they gather in a ro...</td>\n",
       "      <td>People are indoors .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Three cheerful ladies sitting at a table doing...</td>\n",
       "      <td>The ladies are discussing what they are going ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Children with painted red faces being sprayed ...</td>\n",
       "      <td>The children are playing a game .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Old man with gray blanket on squatting against...</td>\n",
       "      <td>Old man squats against a wall .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>A person in a blue plaid shirt is writing on a...</td>\n",
       "      <td>The person is wearing blue jeans .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Two dogs play with tennis ball in field .</td>\n",
       "      <td>The dogs are romping across the field .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>A young dark-haired woman crouches on the bank...</td>\n",
       "      <td>A woman washes dishes .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>A young girl sits on a blue bench drinking out...</td>\n",
       "      <td>A girl is drinking through a straw on a humid ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>A line of people waiting outside The Magpie ca...</td>\n",
       "      <td>A man makes a sandwich .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>A woman wearing a yellow and white outfit is e...</td>\n",
       "      <td>A woman in a brightly colored outfit exits the...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>A dog is running through an obstacle course in...</td>\n",
       "      <td>A dog is competing in a contest</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>A lady sitting on a bench that is against a bu...</td>\n",
       "      <td>Nobody is sitting</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>A long-beaked bird in mid-flight .</td>\n",
       "      <td>A rat running on a wheel .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>A young couple sit on the couch , the woman we...</td>\n",
       "      <td>Two brothers sit on the couch</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>A woman is holding a dog on a leash in front o...</td>\n",
       "      <td>The woman is swimming laps at the pool</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>A small girl learning to fold some clothes .</td>\n",
       "      <td>A boy is playing with a toy trick .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>This is a man in a photo booth .</td>\n",
       "      <td>A man in a photo booth at a carnival .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Two men boxing a ring while one boxer is hitti...</td>\n",
       "      <td>They are playing ring around the rosy .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Dog running down paved walkway near a Japanese...</td>\n",
       "      <td>A pitbull running outside .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>A young man is washing his hair , brushing his...</td>\n",
       "      <td>The young man is grooming himself .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Two women looking at the camera and a man look...</td>\n",
       "      <td>No one is looking at the camera .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>A scientist with a checkered shirt on is looki...</td>\n",
       "      <td>A scientist is using a microscope .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>A little girl in a pink Dora shirt with a pink...</td>\n",
       "      <td>The girl has brown hair .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>A man sits beside parked cars on a city street .</td>\n",
       "      <td>A man is sitting .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>A race car speeding on the track .</td>\n",
       "      <td>A race car is in movement .</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>An old bearded man plays a hand flute on the s...</td>\n",
       "      <td>An old bearded man plays a board game on the s...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>A small girl is unwrapping a green present wit...</td>\n",
       "      <td>It 's Christmas</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>A town worker working on electrical equipment .</td>\n",
       "      <td>The worker is off work for the day .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>A young child sits on some pillows with a gree...</td>\n",
       "      <td>A young man competes in a tennis championship .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>a maintenance worker at the airport carries a ...</td>\n",
       "      <td>A girl follows her father through the airport .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>A man uses stereo equipment .</td>\n",
       "      <td>He is changing the equalization .</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>A teenage girl in winter clothes slides down a...</td>\n",
       "      <td>A girl is on a beach with a blue sled .</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence1  \\\n",
       "0    Three women on a stage , one wearing red shoes...   \n",
       "1    Four people sit on a subway two read books , o...   \n",
       "2    bicycles stationed while a group of people soc...   \n",
       "3                    Man in overalls with two horses .   \n",
       "4    Man observes a wavelength given off by an elec...   \n",
       "5                   Two people are in a green forest .   \n",
       "6    Two men are listening to music through headpho...   \n",
       "7    Two women , one walking her dog the other push...   \n",
       "8    A group of numbered participants walk down the...   \n",
       "9    Three people and a white dog are sitting in th...   \n",
       "10   A man wearing glasses is vacuuming an architec...   \n",
       "11   A large group of people stand outside on a roa...   \n",
       "12     A little boy watches a Ferris Wheel in motion .   \n",
       "13   Man in white shirt and blue jeans looking to t...   \n",
       "14   A man in a dark floral shirt and black jeans w...   \n",
       "15       Two men help an injured player on the field .   \n",
       "16   A woman in a light blue jacket is riding a bike .   \n",
       "17   A group of people dressed in Santa Claus suits...   \n",
       "18   A red jeep hangs from the edge of a rocky clif...   \n",
       "19   Two kids on a boat , one with a paddle , and t...   \n",
       "20   A woman is sitting in a street market stand wh...   \n",
       "21   A group of people are sitting under umbrellas ...   \n",
       "22   A boy riding on a carnival ride turns around f...   \n",
       "23   People walk amongst a traffic jam in a crowded...   \n",
       "24                 A live band on a lawn jamming out .   \n",
       "25                       man grilling fish on barbecue   \n",
       "26   A lone , 2-3 year old blond child in a blue ja...   \n",
       "27   A chef speaks into a microphone about a mixed ...   \n",
       "28   Many people are smiling as they gather in a ro...   \n",
       "29   Three cheerful ladies sitting at a table doing...   \n",
       "..                                                 ...   \n",
       "970  Children with painted red faces being sprayed ...   \n",
       "971  Old man with gray blanket on squatting against...   \n",
       "972  A person in a blue plaid shirt is writing on a...   \n",
       "973          Two dogs play with tennis ball in field .   \n",
       "974  A young dark-haired woman crouches on the bank...   \n",
       "975  A young girl sits on a blue bench drinking out...   \n",
       "976  A line of people waiting outside The Magpie ca...   \n",
       "977  A woman wearing a yellow and white outfit is e...   \n",
       "978  A dog is running through an obstacle course in...   \n",
       "979  A lady sitting on a bench that is against a bu...   \n",
       "980                 A long-beaked bird in mid-flight .   \n",
       "981  A young couple sit on the couch , the woman we...   \n",
       "982  A woman is holding a dog on a leash in front o...   \n",
       "983       A small girl learning to fold some clothes .   \n",
       "984                   This is a man in a photo booth .   \n",
       "985  Two men boxing a ring while one boxer is hitti...   \n",
       "986  Dog running down paved walkway near a Japanese...   \n",
       "987  A young man is washing his hair , brushing his...   \n",
       "988  Two women looking at the camera and a man look...   \n",
       "989  A scientist with a checkered shirt on is looki...   \n",
       "990  A little girl in a pink Dora shirt with a pink...   \n",
       "991   A man sits beside parked cars on a city street .   \n",
       "992                 A race car speeding on the track .   \n",
       "993  An old bearded man plays a hand flute on the s...   \n",
       "994  A small girl is unwrapping a green present wit...   \n",
       "995    A town worker working on electrical equipment .   \n",
       "996  A young child sits on some pillows with a gree...   \n",
       "997  a maintenance worker at the airport carries a ...   \n",
       "998                      A man uses stereo equipment .   \n",
       "999  A teenage girl in winter clothes slides down a...   \n",
       "\n",
       "                                             sentence2          label  \n",
       "0            There are two women standing on the stage  contradiction  \n",
       "1    Multiple people are on a subway together , wit...     entailment  \n",
       "2       People get together near a stand of bicycles .     entailment  \n",
       "3                    a man in overalls with two horses     entailment  \n",
       "4    The man is examining what wavelength is given ...     entailment  \n",
       "5                             The forest is not dead .     entailment  \n",
       "6                            Two men listen to music .     entailment  \n",
       "7                               There is a snowstorm .  contradiction  \n",
       "8    Participants wait for the beginning of the wal...        neutral  \n",
       "9    Three dogs and a person are sitting in the snow .  contradiction  \n",
       "10                            There is a man vaucuming     entailment  \n",
       "11   One group of people are watching what another ...     entailment  \n",
       "12     A boy is waiting in line for the Ferris Wheel .        neutral  \n",
       "13                           Man has a blue shirt on .  contradiction  \n",
       "14   A man walks past a newly painted mural of a wo...     entailment  \n",
       "15      Some men help an injured player on the field .     entailment  \n",
       "16         A woman in a jacket riding a bike to work .        neutral  \n",
       "17                     A band plays at a beach party .        neutral  \n",
       "18                                The vehicle is red .     entailment  \n",
       "19                      A kid is wearing a life vest .     entailment  \n",
       "20                   The woman is in a street market .     entailment  \n",
       "21                                    It is a saturday        neutral  \n",
       "22                                      A human riding     entailment  \n",
       "23   The traffic is halted and people are walking b...     entailment  \n",
       "24      A band is practicing new tunes in the garage .  contradiction  \n",
       "25                         The man likes to eat fish .        neutral  \n",
       "26             The couch is pointed toward the front .  contradiction  \n",
       "27         a chef speaks into a microphone near a bowl     entailment  \n",
       "28                                People are indoors .     entailment  \n",
       "29   The ladies are discussing what they are going ...        neutral  \n",
       "..                                                 ...            ...  \n",
       "970                  The children are playing a game .        neutral  \n",
       "971                    Old man squats against a wall .     entailment  \n",
       "972                 The person is wearing blue jeans .        neutral  \n",
       "973            The dogs are romping across the field .     entailment  \n",
       "974                            A woman washes dishes .     entailment  \n",
       "975  A girl is drinking through a straw on a humid ...        neutral  \n",
       "976                           A man makes a sandwich .  contradiction  \n",
       "977  A woman in a brightly colored outfit exits the...     entailment  \n",
       "978                    A dog is competing in a contest        neutral  \n",
       "979                                  Nobody is sitting  contradiction  \n",
       "980                         A rat running on a wheel .  contradiction  \n",
       "981                      Two brothers sit on the couch  contradiction  \n",
       "982             The woman is swimming laps at the pool  contradiction  \n",
       "983                A boy is playing with a toy trick .  contradiction  \n",
       "984             A man in a photo booth at a carnival .        neutral  \n",
       "985            They are playing ring around the rosy .  contradiction  \n",
       "986                        A pitbull running outside .        neutral  \n",
       "987                The young man is grooming himself .     entailment  \n",
       "988                  No one is looking at the camera .  contradiction  \n",
       "989                A scientist is using a microscope .     entailment  \n",
       "990                          The girl has brown hair .        neutral  \n",
       "991                                 A man is sitting .     entailment  \n",
       "992                        A race car is in movement .     entailment  \n",
       "993  An old bearded man plays a board game on the s...  contradiction  \n",
       "994                                    It 's Christmas        neutral  \n",
       "995               The worker is off work for the day .  contradiction  \n",
       "996    A young man competes in a tennis championship .  contradiction  \n",
       "997    A girl follows her father through the airport .  contradiction  \n",
       "998                  He is changing the equalization .        neutral  \n",
       "999            A girl is on a beach with a blue sled .  contradiction  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file\n",
    "# ['entailment', 'contradiction', 'neutral'], [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
